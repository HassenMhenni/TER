{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "64d3402b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.pyplot._IonContext at 0x1aecb2096a0>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from __future__ import print_function, division\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import torch.backends.cudnn as cudnn\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "\n",
    "cudnn.benchmark = True\n",
    "plt.ion()   # interactive mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3bacda10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Data augmentation and normalization for training\n",
    "# Just normalization for validation\n",
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.RandomResizedCrop(224),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "}\n",
    "\n",
    "data_dir = 'data'\n",
    "\n",
    "image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x),\n",
    "                                          data_transforms[x])\n",
    "                  for x in ['train', 'val']}\n",
    "dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=8,\n",
    "                                             shuffle=True, num_workers=4)\n",
    "              for x in ['train', 'val']}\n",
    "\n",
    "dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val']}\n",
    "\n",
    "class_names = image_datasets['train'].classes\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "74031917",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train function and stock the values in the lists\n",
    "def train_model(model, criterion, optimizer, scheduler, num_epochs=10):\n",
    "    since = time.time()\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "    \n",
    "    # create lists to store the results for each epoch of the trained model\n",
    "    train_loss = []\n",
    "    val_loss = []\n",
    "    train_acc = []\n",
    "    val_acc = []\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f'Epoch {epoch}/{num_epochs - 1}')\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "            # Iterate over data.\n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    loss = criterion(outputs, labels)\n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "                # statistics\n",
    "\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "            if phase == 'train':\n",
    "                scheduler.step()\n",
    "\n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
    "\n",
    "            print(f'{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n",
    "\n",
    "            # deep copy the model\n",
    "            if phase == 'val' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "            if phase == 'train':\n",
    "                train_loss.append(epoch_loss)\n",
    "                train_acc.append(epoch_acc)\n",
    "            else:\n",
    "                val_loss.append(epoch_loss)\n",
    "                val_acc.append(epoch_acc)\n",
    "        print()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print(f'Training complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')\n",
    "    print(f'Best val Acc: {best_acc:4f}')\n",
    "\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return [model,val_acc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "df7fa45c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def grid_search_cv(param_grid, criterion, dataloaders, dataset_sizes):\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "\n",
    "    best_model = None\n",
    "    best_acc = 0.0\n",
    "    \n",
    "    for lr in param_grid['lr']:\n",
    "        for weight_decay in param_grid['weight_decay']:\n",
    "            \n",
    "            print(f'testing the following combination {lr} learning rate and {weight_decay} weight decay')\n",
    "            \n",
    "            model = models.resnet18(pretrained=True)\n",
    "            model = model.to(device)\n",
    "            \n",
    "            optimizer = torch.optim.SGD(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "            scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)\n",
    "        \n",
    "            trained_model = train_model(model, criterion, optimizer, scheduler)\n",
    "            val_acc = trained_model[1]\n",
    "            \n",
    "            if best_acc < max(val_acc):\n",
    "                best_acc = max(val_acc)\n",
    "                best_model = copy.deepcopy(trained_model[0])\n",
    "                best_lr = lr\n",
    "                best_weight_decay = weight_decay\n",
    "                \n",
    "    print(f'the best parameters combination is a learning rate of {best_lr} and weight decay of {best_weight_decay}')\n",
    "    return best_model, best_lr, best_weight_decay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "87705ffa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "79203ff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "274a1a41",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'lr': [0.001, 0.01, 0.1], 'weight_decay': [1e-4, 1e-6, 1e-8]}\n",
    "criterion = nn.CrossEntropyLoss().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a8c0bdc8",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing the following combination 0.001 learning rate and 0.0001 weight decay\n",
      "Epoch 0/9\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thoma\\anaconda3\\lib\\site-packages\\torch\\nn\\functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  ..\\c10/core/TensorImpl.h:1156.)\n",
      "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.9132 Acc: 0.7139\n",
      "val Loss: 0.2191 Acc: 0.9279\n",
      "\n",
      "Epoch 1/9\n",
      "----------\n",
      "train Loss: 0.4611 Acc: 0.8263\n",
      "val Loss: 0.1695 Acc: 0.9471\n",
      "\n",
      "Epoch 2/9\n",
      "----------\n",
      "train Loss: 0.3924 Acc: 0.8524\n",
      "val Loss: 0.1440 Acc: 0.9532\n",
      "\n",
      "Epoch 3/9\n",
      "----------\n",
      "train Loss: 0.3668 Acc: 0.8591\n",
      "val Loss: 0.1365 Acc: 0.9564\n",
      "\n",
      "Epoch 4/9\n",
      "----------\n",
      "train Loss: 0.3351 Acc: 0.8726\n",
      "val Loss: 0.1119 Acc: 0.9654\n",
      "\n",
      "Epoch 5/9\n",
      "----------\n",
      "train Loss: 0.3190 Acc: 0.8818\n",
      "val Loss: 0.1030 Acc: 0.9675\n",
      "\n",
      "Epoch 6/9\n",
      "----------\n",
      "train Loss: 0.3032 Acc: 0.8870\n",
      "val Loss: 0.1103 Acc: 0.9650\n",
      "\n",
      "Epoch 7/9\n",
      "----------\n",
      "train Loss: 0.2838 Acc: 0.8926\n",
      "val Loss: 0.0996 Acc: 0.9693\n",
      "\n",
      "Epoch 8/9\n",
      "----------\n",
      "train Loss: 0.2802 Acc: 0.8920\n",
      "val Loss: 0.0970 Acc: 0.9693\n",
      "\n",
      "Epoch 9/9\n",
      "----------\n",
      "train Loss: 0.2849 Acc: 0.8917\n",
      "val Loss: 0.0969 Acc: 0.9689\n",
      "\n",
      "Training complete in 12m 40s\n",
      "Best val Acc: 0.969286\n",
      "testing the following combination 0.001 learning rate and 1e-06 weight decay\n",
      "Epoch 0/9\n",
      "----------\n",
      "train Loss: 0.9101 Acc: 0.7228\n",
      "val Loss: 0.2075 Acc: 0.9286\n",
      "\n",
      "Epoch 1/9\n",
      "----------\n",
      "train Loss: 0.4551 Acc: 0.8307\n",
      "val Loss: 0.1511 Acc: 0.9511\n",
      "\n",
      "Epoch 2/9\n",
      "----------\n",
      "train Loss: 0.3895 Acc: 0.8533\n",
      "val Loss: 0.1373 Acc: 0.9571\n",
      "\n",
      "Epoch 3/9\n",
      "----------\n",
      "train Loss: 0.3531 Acc: 0.8662\n",
      "val Loss: 0.1297 Acc: 0.9564\n",
      "\n",
      "Epoch 4/9\n",
      "----------\n",
      "train Loss: 0.3383 Acc: 0.8748\n",
      "val Loss: 0.1161 Acc: 0.9600\n",
      "\n",
      "Epoch 5/9\n",
      "----------\n",
      "train Loss: 0.3195 Acc: 0.8775\n",
      "val Loss: 0.1134 Acc: 0.9618\n",
      "\n",
      "Epoch 6/9\n",
      "----------\n",
      "train Loss: 0.2983 Acc: 0.8873\n",
      "val Loss: 0.1054 Acc: 0.9675\n",
      "\n",
      "Epoch 7/9\n",
      "----------\n",
      "train Loss: 0.2839 Acc: 0.8924\n",
      "val Loss: 0.1040 Acc: 0.9664\n",
      "\n",
      "Epoch 8/9\n",
      "----------\n",
      "train Loss: 0.2864 Acc: 0.8921\n",
      "val Loss: 0.1096 Acc: 0.9657\n",
      "\n",
      "Epoch 9/9\n",
      "----------\n",
      "train Loss: 0.2807 Acc: 0.8962\n",
      "val Loss: 0.1003 Acc: 0.9657\n",
      "\n",
      "Training complete in 12m 42s\n",
      "Best val Acc: 0.967500\n",
      "testing the following combination 0.001 learning rate and 1e-08 weight decay\n",
      "Epoch 0/9\n",
      "----------\n",
      "train Loss: 0.9194 Acc: 0.7146\n",
      "val Loss: 0.2027 Acc: 0.9375\n",
      "\n",
      "Epoch 1/9\n",
      "----------\n",
      "train Loss: 0.4709 Acc: 0.8273\n",
      "val Loss: 0.1805 Acc: 0.9393\n",
      "\n",
      "Epoch 2/9\n",
      "----------\n",
      "train Loss: 0.4059 Acc: 0.8453\n",
      "val Loss: 0.1391 Acc: 0.9511\n",
      "\n",
      "Epoch 3/9\n",
      "----------\n",
      "train Loss: 0.3582 Acc: 0.8654\n",
      "val Loss: 0.1479 Acc: 0.9511\n",
      "\n",
      "Epoch 4/9\n",
      "----------\n",
      "train Loss: 0.3403 Acc: 0.8736\n",
      "val Loss: 0.1234 Acc: 0.9600\n",
      "\n",
      "Epoch 5/9\n",
      "----------\n",
      "train Loss: 0.3179 Acc: 0.8801\n",
      "val Loss: 0.1337 Acc: 0.9561\n",
      "\n",
      "Epoch 6/9\n",
      "----------\n",
      "train Loss: 0.3018 Acc: 0.8857\n",
      "val Loss: 0.1041 Acc: 0.9668\n",
      "\n",
      "Epoch 7/9\n",
      "----------\n",
      "train Loss: 0.2900 Acc: 0.8899\n",
      "val Loss: 0.1045 Acc: 0.9664\n",
      "\n",
      "Epoch 8/9\n",
      "----------\n",
      "train Loss: 0.2803 Acc: 0.8917\n",
      "val Loss: 0.1031 Acc: 0.9668\n",
      "\n",
      "Epoch 9/9\n",
      "----------\n",
      "train Loss: 0.2740 Acc: 0.8956\n",
      "val Loss: 0.1029 Acc: 0.9668\n",
      "\n",
      "Training complete in 12m 27s\n",
      "Best val Acc: 0.966786\n",
      "testing the following combination 0.01 learning rate and 0.0001 weight decay\n",
      "Epoch 0/9\n",
      "----------\n",
      "train Loss: 0.6231 Acc: 0.7810\n",
      "val Loss: 0.1463 Acc: 0.9518\n",
      "\n",
      "Epoch 1/9\n",
      "----------\n",
      "train Loss: 0.3704 Acc: 0.8640\n",
      "val Loss: 0.1191 Acc: 0.9646\n",
      "\n",
      "Epoch 2/9\n",
      "----------\n",
      "train Loss: 0.3116 Acc: 0.8824\n",
      "val Loss: 0.1040 Acc: 0.9654\n",
      "\n",
      "Epoch 3/9\n",
      "----------\n",
      "train Loss: 0.2871 Acc: 0.8926\n",
      "val Loss: 0.0999 Acc: 0.9693\n",
      "\n",
      "Epoch 4/9\n",
      "----------\n",
      "train Loss: 0.2731 Acc: 0.8983\n",
      "val Loss: 0.1321 Acc: 0.9575\n",
      "\n",
      "Epoch 5/9\n",
      "----------\n",
      "train Loss: 0.2571 Acc: 0.9035\n",
      "val Loss: 0.0921 Acc: 0.9707\n",
      "\n",
      "Epoch 6/9\n",
      "----------\n",
      "train Loss: 0.2445 Acc: 0.9063\n",
      "val Loss: 0.0781 Acc: 0.9768\n",
      "\n",
      "Epoch 7/9\n",
      "----------\n",
      "train Loss: 0.2094 Acc: 0.9192\n",
      "val Loss: 0.0745 Acc: 0.9779\n",
      "\n",
      "Epoch 8/9\n",
      "----------\n",
      "train Loss: 0.2059 Acc: 0.9190\n",
      "val Loss: 0.0777 Acc: 0.9743\n",
      "\n",
      "Epoch 9/9\n",
      "----------\n",
      "train Loss: 0.1967 Acc: 0.9239\n",
      "val Loss: 0.0719 Acc: 0.9782\n",
      "\n",
      "Training complete in 12m 15s\n",
      "Best val Acc: 0.978214\n",
      "testing the following combination 0.01 learning rate and 1e-06 weight decay\n",
      "Epoch 0/9\n",
      "----------\n",
      "train Loss: 0.6120 Acc: 0.7867\n",
      "val Loss: 0.1400 Acc: 0.9546\n",
      "\n",
      "Epoch 1/9\n",
      "----------\n",
      "train Loss: 0.3616 Acc: 0.8635\n",
      "val Loss: 0.1232 Acc: 0.9596\n",
      "\n",
      "Epoch 2/9\n",
      "----------\n",
      "train Loss: 0.3078 Acc: 0.8828\n",
      "val Loss: 0.1204 Acc: 0.9629\n",
      "\n",
      "Epoch 3/9\n",
      "----------\n",
      "train Loss: 0.2815 Acc: 0.8940\n",
      "val Loss: 0.1097 Acc: 0.9604\n",
      "\n",
      "Epoch 4/9\n",
      "----------\n",
      "train Loss: 0.2734 Acc: 0.8943\n",
      "val Loss: 0.0993 Acc: 0.9682\n",
      "\n",
      "Epoch 5/9\n",
      "----------\n",
      "train Loss: 0.2651 Acc: 0.8979\n",
      "val Loss: 0.0977 Acc: 0.9657\n",
      "\n",
      "Epoch 6/9\n",
      "----------\n",
      "train Loss: 0.2499 Acc: 0.9050\n",
      "val Loss: 0.0880 Acc: 0.9721\n",
      "\n",
      "Epoch 7/9\n",
      "----------\n",
      "train Loss: 0.2117 Acc: 0.9174\n",
      "val Loss: 0.0767 Acc: 0.9761\n",
      "\n",
      "Epoch 8/9\n",
      "----------\n",
      "train Loss: 0.1943 Acc: 0.9237\n",
      "val Loss: 0.0726 Acc: 0.9764\n",
      "\n",
      "Epoch 9/9\n",
      "----------\n",
      "train Loss: 0.1969 Acc: 0.9221\n",
      "val Loss: 0.0700 Acc: 0.9786\n",
      "\n",
      "Training complete in 12m 24s\n",
      "Best val Acc: 0.978571\n",
      "testing the following combination 0.01 learning rate and 1e-08 weight decay\n",
      "Epoch 0/9\n",
      "----------\n",
      "train Loss: 0.6396 Acc: 0.7762\n",
      "val Loss: 0.2128 Acc: 0.9361\n",
      "\n",
      "Epoch 1/9\n",
      "----------\n",
      "train Loss: 0.3760 Acc: 0.8588\n",
      "val Loss: 0.1148 Acc: 0.9664\n",
      "\n",
      "Epoch 2/9\n",
      "----------\n",
      "train Loss: 0.3175 Acc: 0.8779\n",
      "val Loss: 0.1148 Acc: 0.9600\n",
      "\n",
      "Epoch 3/9\n",
      "----------\n",
      "train Loss: 0.2835 Acc: 0.8928\n",
      "val Loss: 0.0947 Acc: 0.9689\n",
      "\n",
      "Epoch 4/9\n",
      "----------\n",
      "train Loss: 0.2737 Acc: 0.8944\n",
      "val Loss: 0.0952 Acc: 0.9679\n",
      "\n",
      "Epoch 5/9\n",
      "----------\n",
      "train Loss: 0.2601 Acc: 0.9016\n",
      "val Loss: 0.1156 Acc: 0.9639\n",
      "\n",
      "Epoch 6/9\n",
      "----------\n",
      "train Loss: 0.2582 Acc: 0.9020\n",
      "val Loss: 0.0875 Acc: 0.9714\n",
      "\n",
      "Epoch 7/9\n",
      "----------\n",
      "train Loss: 0.2084 Acc: 0.9195\n",
      "val Loss: 0.0725 Acc: 0.9757\n",
      "\n",
      "Epoch 8/9\n",
      "----------\n",
      "train Loss: 0.1957 Acc: 0.9252\n",
      "val Loss: 0.0742 Acc: 0.9750\n",
      "\n",
      "Epoch 9/9\n",
      "----------\n",
      "train Loss: 0.1910 Acc: 0.9246\n",
      "val Loss: 0.0739 Acc: 0.9743\n",
      "\n",
      "Training complete in 30m 47s\n",
      "Best val Acc: 0.975714\n",
      "testing the following combination 0.1 learning rate and 0.0001 weight decay\n",
      "Epoch 0/9\n",
      "----------\n",
      "train Loss: 1.3463 Acc: 0.5045\n",
      "val Loss: 0.6104 Acc: 0.7514\n",
      "\n",
      "Epoch 1/9\n",
      "----------\n",
      "train Loss: 0.7061 Acc: 0.7215\n",
      "val Loss: 0.3568 Acc: 0.8854\n",
      "\n",
      "Epoch 2/9\n",
      "----------\n",
      "train Loss: 0.5305 Acc: 0.7970\n",
      "val Loss: 0.2547 Acc: 0.9071\n",
      "\n",
      "Epoch 3/9\n",
      "----------\n",
      "train Loss: 0.4487 Acc: 0.8289\n",
      "val Loss: 0.2313 Acc: 0.9271\n",
      "\n",
      "Epoch 4/9\n",
      "----------\n",
      "train Loss: 0.3974 Acc: 0.8499\n",
      "val Loss: 0.1764 Acc: 0.9443\n",
      "\n",
      "Epoch 5/9\n",
      "----------\n",
      "train Loss: 0.3744 Acc: 0.8573\n",
      "val Loss: 0.2171 Acc: 0.9314\n",
      "\n",
      "Epoch 6/9\n",
      "----------\n",
      "train Loss: 0.3543 Acc: 0.8642\n",
      "val Loss: 0.1301 Acc: 0.9561\n",
      "\n",
      "Epoch 7/9\n",
      "----------\n",
      "train Loss: 0.2695 Acc: 0.8933\n",
      "val Loss: 0.1021 Acc: 0.9675\n",
      "\n",
      "Epoch 8/9\n",
      "----------\n",
      "train Loss: 0.2524 Acc: 0.9002\n",
      "val Loss: 0.0998 Acc: 0.9671\n",
      "\n",
      "Epoch 9/9\n",
      "----------\n",
      "train Loss: 0.2461 Acc: 0.9048\n",
      "val Loss: 0.0942 Acc: 0.9693\n",
      "\n",
      "Training complete in 64m 56s\n",
      "Best val Acc: 0.969286\n",
      "testing the following combination 0.1 learning rate and 1e-06 weight decay\n",
      "Epoch 0/9\n",
      "----------\n",
      "train Loss: 1.4837 Acc: 0.4459\n",
      "val Loss: 0.8092 Acc: 0.6407\n",
      "\n",
      "Epoch 1/9\n",
      "----------\n",
      "train Loss: 0.8423 Acc: 0.6535\n",
      "val Loss: 0.6450 Acc: 0.7625\n",
      "\n",
      "Epoch 2/9\n",
      "----------\n",
      "train Loss: 0.6432 Acc: 0.7470\n",
      "val Loss: 0.3474 Acc: 0.8811\n",
      "\n",
      "Epoch 3/9\n",
      "----------\n",
      "train Loss: 0.5450 Acc: 0.7878\n",
      "val Loss: 0.3805 Acc: 0.8743\n",
      "\n",
      "Epoch 4/9\n",
      "----------\n",
      "train Loss: 0.4693 Acc: 0.8218\n",
      "val Loss: 0.2666 Acc: 0.9107\n",
      "\n",
      "Epoch 5/9\n",
      "----------\n",
      "train Loss: 0.4246 Acc: 0.8350\n",
      "val Loss: 0.4900 Acc: 0.8204\n",
      "\n",
      "Epoch 6/9\n",
      "----------\n",
      "train Loss: 0.3967 Acc: 0.8496\n",
      "val Loss: 0.2126 Acc: 0.9311\n",
      "\n",
      "Epoch 7/9\n",
      "----------\n",
      "train Loss: 0.2972 Acc: 0.8836\n",
      "val Loss: 0.1300 Acc: 0.9554\n",
      "\n",
      "Epoch 8/9\n",
      "----------\n",
      "train Loss: 0.2773 Acc: 0.8925\n",
      "val Loss: 0.1203 Acc: 0.9582\n",
      "\n",
      "Epoch 9/9\n",
      "----------\n",
      "train Loss: 0.2679 Acc: 0.8986\n",
      "val Loss: 0.1191 Acc: 0.9582\n",
      "\n",
      "Training complete in 11m 42s\n",
      "Best val Acc: 0.958214\n",
      "testing the following combination 0.1 learning rate and 1e-08 weight decay\n",
      "Epoch 0/9\n",
      "----------\n",
      "train Loss: 1.4588 Acc: 0.4522\n",
      "val Loss: 0.8517 Acc: 0.6268\n",
      "\n",
      "Epoch 1/9\n",
      "----------\n",
      "train Loss: 0.7604 Acc: 0.6986\n",
      "val Loss: 0.3289 Acc: 0.8836\n",
      "\n",
      "Epoch 2/9\n",
      "----------\n",
      "train Loss: 0.5443 Acc: 0.7916\n",
      "val Loss: 0.2374 Acc: 0.9229\n",
      "\n",
      "Epoch 3/9\n",
      "----------\n",
      "train Loss: 0.4431 Acc: 0.8329\n",
      "val Loss: 0.3012 Acc: 0.8786\n",
      "\n",
      "Epoch 4/9\n",
      "----------\n",
      "train Loss: 0.3880 Acc: 0.8528\n",
      "val Loss: 0.1995 Acc: 0.9339\n",
      "\n",
      "Epoch 5/9\n",
      "----------\n",
      "train Loss: 0.3670 Acc: 0.8604\n",
      "val Loss: 0.1785 Acc: 0.9518\n",
      "\n",
      "Epoch 6/9\n",
      "----------\n",
      "train Loss: 0.3356 Acc: 0.8679\n",
      "val Loss: 0.1589 Acc: 0.9432\n",
      "\n",
      "Epoch 7/9\n",
      "----------\n",
      "train Loss: 0.2639 Acc: 0.8982\n",
      "val Loss: 0.0991 Acc: 0.9657\n",
      "\n",
      "Epoch 8/9\n",
      "----------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.2487 Acc: 0.9045\n",
      "val Loss: 0.0968 Acc: 0.9657\n",
      "\n",
      "Epoch 9/9\n",
      "----------\n",
      "train Loss: 0.2438 Acc: 0.9048\n",
      "val Loss: 0.0882 Acc: 0.9721\n",
      "\n",
      "Training complete in 11m 48s\n",
      "Best val Acc: 0.972143\n",
      "the best parameters combination is a learning rate of 0.01 and weight decay of 1e-06\n"
     ]
    }
   ],
   "source": [
    "best_model = grid_search_cv(param_grid, criterion, dataloaders, dataset_sizes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9af8a35d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save the model\n",
    "torch.save(best_model[0].state_dict(), 'best_ResNet.pth')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
